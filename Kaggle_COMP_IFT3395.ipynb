{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importations des libraires"
      ],
      "metadata": {
        "id": "_8qBHU8Ja0cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "88WiTthu5IVY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzip les zip folders , on utilise Linux car on est des informaticiens forts :)"
      ],
      "metadata": {
        "id": "hV6hz5rJa3_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "metadata": {
        "id": "N9f_wxXY5U-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddac451d-5fb3-404d-e578-60e28701291f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on fait juste diviser no data , et on utilise panda wooo"
      ],
      "metadata": {
        "id": "5pPkiLJ_bFYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "data_array = df.to_numpy()\n",
        "test_array = df_test.to_numpy()"
      ],
      "metadata": {
        "id": "t_9UUC9D5S2b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number = data_array[:, 0]\n",
        "\n",
        "label = data_array[:, -1]\n",
        "\n",
        "features = data_array[:, 1:-1]\n",
        "\n",
        "test_number = test_array[:, 0]\n",
        "\n",
        "\n",
        "test_features = test_array[:, 1:]\n"
      ],
      "metadata": {
        "id": "bZ3O0gMm9bbO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what a library ! ca nous tire les k features les plus importants !!!!! MAGIC"
      ],
      "metadata": {
        "id": "ZEr3fPR1bMs5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UQccbog948I_"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_new = selector.fit_transform(features, label)\n",
        "selected_feature_indices = selector.get_support(indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_indices = selected_feature_indices\n",
        "\n",
        "X_test_new = test_features[:, col_indices]\n"
      ],
      "metadata": {
        "id": "vClYHNoUGSeB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECK WHAT A LIBRARY ALSO CA SPLIT LES DONNES !!!!!!!!!!!!!!!!!!!!!"
      ],
      "metadata": {
        "id": "ay9B5MV0bTpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_new, label, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pQIN-fwjD0H8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OHOHOOOOOO ITS GETTING CRAZIER >>>>>>> WE'RE ADDING DATA POINTS"
      ],
      "metadata": {
        "id": "0KSnFBUfbXSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_majority = X_new[label == 0]\n",
        "X_minority = X_new[label == 1]\n",
        "X_class2 = X_new[label == 2]\n",
        "\n",
        "majority_percent = 0.33\n",
        "minority_percent = 10\n",
        "class2_percent = 3\n",
        "\n",
        "desired_majority_samples = int(len(X_majority) * majority_percent)\n",
        "desired_minority_samples = int(len(X_minority) * minority_percent)\n",
        "desired_class2_samples = int(len(X_class2) * class2_percent)\n",
        "\n",
        "X_majority_resampled = resample(X_majority, n_samples=desired_majority_samples, random_state=42)\n",
        "X_minority_resampled = resample(X_minority, n_samples=desired_minority_samples, random_state=42)\n",
        "X_class2_resampled = resample(X_class2, n_samples=desired_class2_samples, random_state=42)\n",
        "\n",
        "X_resampled = np.concatenate((X_majority_resampled, X_minority_resampled, X_class2_resampled), axis=0)\n",
        "y_resampled = np.concatenate((np.full(desired_majority_samples, 0), np.full(desired_minority_samples, 1), np.full(desired_class2_samples, 2)))\n",
        "\n"
      ],
      "metadata": {
        "id": "52ZIums1DA3A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAL VAL VAL"
      ],
      "metadata": {
        "id": "rADduoUVbfBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "svm_classifier = SVC(kernel='rbf', C=1, gamma=0.1)\n",
        "\n",
        "svm_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_val)\n",
        "\n",
        "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
        "print(\"SVM Accuracy:\", accuracy_svm)\n",
        "\n",
        "report_svm = classification_report(y_val, y_pred_svm)\n",
        "print(\"SVM Classification Report:\\n\", report_svm)\n"
      ],
      "metadata": {
        "id": "BItRalWCDPHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5ec235-373a-4e43-8f77-63bd6f646636"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8779043789097408\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.86      0.92      7069\n",
            "         1.0       0.62      0.99      0.77       364\n",
            "         2.0       0.64      0.95      0.76      1519\n",
            "\n",
            "    accuracy                           0.88      8952\n",
            "   macro avg       0.75      0.93      0.82      8952\n",
            "weighted avg       0.92      0.88      0.89      8952\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.count_nonzero(y_pred_svm == 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2StnDZHJEmUv",
        "outputId": "ae5b7639-abc7-421f-881b-08017d168af3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "803"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST TEST TEST"
      ],
      "metadata": {
        "id": "jT3TwPjKbhGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svm_classifier = SVC(kernel='rbf', C=1, gamma=0.1)\n",
        "\n",
        "svm_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_test_new)\n",
        "\n"
      ],
      "metadata": {
        "id": "6bYpFJLvFyxc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.count_nonzero(y_pred_svm == 2)"
      ],
      "metadata": {
        "id": "b7WBAbioHGcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaed5cf-e486-44a6-df65-0f5a02cf07da"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUTPUT"
      ],
      "metadata": {
        "id": "FVHVtNv4bjcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.hstack((test_number[:, np.newaxis], y_pred_svm[:, np.newaxis]))\n",
        "\n",
        "csv_file = 'preds.csv'\n",
        "\n",
        "header_str = \"SNo,Label\"\n",
        "\n",
        "\n",
        "# Use numpy.savetxt to save the array to a CSV file\n",
        "np.savetxt(csv_file, result, delimiter=',', header=header_str,fmt='%f',comments='')"
      ],
      "metadata": {
        "id": "St3ebuFYAiKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}