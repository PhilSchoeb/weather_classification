{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file to get data\n",
    "file1 = open(\"train.csv\")\n",
    "file2 = open(\"test.csv\")\n",
    "\n",
    "csvreader1 = csv.reader(file1)\n",
    "csvreader2 = csv.reader(file2)\n",
    "\n",
    "header_train = []\n",
    "header_train = next(csvreader1)\n",
    "\n",
    "next(csvreader2)\n",
    "\n",
    "data_train = []\n",
    "for row in csvreader1:\n",
    "    data_train.append(row)\n",
    "\n",
    "data_test = []\n",
    "for row in csvreader2:\n",
    "    data_test.append(row)\n",
    "\n",
    "file1.close()\n",
    "file2.close()\n",
    "\n",
    "    # Turn our data in np.array and remove the first attribue which is just numeration\n",
    "data_train = np.array(data_train, dtype=float)\n",
    "data_train = np.delete(data_train, 0, axis=1)\n",
    "\n",
    "data_test = np.array(data_test, dtype=float)\n",
    "data_test = np.delete(data_test, 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMaxLikelihood:\n",
    "    def __init__(self, n_dims, cov_type='isotropic'):\n",
    "        self.cov_type = cov_type\n",
    "        self.n_dims = n_dims\n",
    "        self.mu = np.zeros(n_dims)\n",
    "        # Nous avons un scalaire comme écart-type car notre modèle est une loi gaussienne isotropique\n",
    "        self.sigma_sq = 1.0\n",
    "\n",
    "    # Pour un jeu d'entraînement, la fonction devrait calculer les estimateur ML de l'espérance et de la variance\n",
    "    def train(self, train_data):\n",
    "        # Ici, nous devons trouver la moyenne et la variance dans train_data et les définir dans self.mu and self.\n",
    "\n",
    "        self.mu = np.mean(train_data, axis=0)\n",
    "\n",
    "        # here we will create t\bhe covariance matrix\n",
    "        if self.cov_type == 'isotropic':\n",
    "            # Identity times sigma square\n",
    "            self.covariance = np.eye(\n",
    "                self.n_dims) * np.sum((train_data - self.mu) ** 2.0) / (self.n_dims * train_data.shape[0])\n",
    "        elif self.cov_type == 'diagonal':\n",
    "            # put the variance on the diagonal\n",
    "            self.covariance = np.diag(np.var(train_data, axis=0))\n",
    "        else:\n",
    "            # Calculate the full covariance matrix\n",
    "            self.covariance = np.cov(train_data, rowvar=False)\n",
    "\n",
    "    # Retourne un vecteur de dimension égale au nombre d'ex. test qui contient les log probabilité de chaque\n",
    "    # exemple test\n",
    "\n",
    "    def loglikelihood(self, test_data):\n",
    "        # Calculer la constante de normalisation de la façon standard, sans raccourci\n",
    "        c = -(np.log(np.sqrt(np.linalg.det(self.covariance))) +\n",
    "              (self.n_dims / 2) * np.log(2 * np.pi))\n",
    "        # Ensuite la log prob\n",
    "        # Notez l'absence d'un second np.dot. Pouvez-vous deviner pourquoi?\n",
    "        log_prob = c - (np.dot((test_data - self.mu), np.linalg.inv(self.covariance))\n",
    "                        * (test_data - self.mu)).sum(axis=1) / 2\n",
    "        return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesClassifier:\n",
    "    def __init__(self, maximum_likelihood_models, priors):\n",
    "        self.maximum_likelihood_models = maximum_likelihood_models\n",
    "        self.priors = priors\n",
    "        if len(self.maximum_likelihood_models) != len(self.priors):\n",
    "            print('The number of ML models must be equal to the number of priors!')\n",
    "        self.n_classes = len(self.maximum_likelihood_models)\n",
    "\n",
    "    # Retourne une matrice de dimension [nb d'ex. test, nb de classes] contenant les log\n",
    "    # probabilités de chaque ex. test sous le modèle entrainé par le MV.\n",
    "    def loglikelihood(self, test_data):\n",
    "\n",
    "        log_pred = np.zeros((test_data.shape[0], self.n_classes))\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            # Ici, nous devrons utiliser maximum_likelihood_models[i] et priors pour remplir\n",
    "            # chaque colonne de log_pred (c'est plus efficace de remplir une colonne à la fois)\n",
    "\n",
    "            log_pred[:, i] = self.maximum_likelihood_models[i].loglikelihood(\n",
    "                test_data) + np.log(self.priors[i])\n",
    "\n",
    "        return log_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data_train[:,0:19]\n",
    "Y_train=data_train[:,-1]\n",
    "\n",
    "X_test = data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "10320\n",
      "10320\n",
      "44760\n",
      "44760\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test[0]))\n",
    "print(len(data_test[0]))\n",
    "print(len(X_train[0]))\n",
    "print(len(data_train[0]))\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(data_test))\n",
    "print(len(X_train))\n",
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(data_train[0]))\n",
    "#print(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_trainClass0=X_train[data_train[:,-1]==0]\n",
    "Data_trainClass1 = X_train[data_train[:, -1] == 1]\n",
    "Data_trainClass2 = X_train[data_train[:, -1] == 2]\n",
    "\n",
    "cov_type = 'full'\n",
    "\n",
    "model_class1 = GaussianMaxLikelihood(19, cov_type)\n",
    "model_class2 = GaussianMaxLikelihood(19, cov_type)\n",
    "model_class3 = GaussianMaxLikelihood(19, cov_type)\n",
    "model_class1.train(Data_trainClass0)\n",
    "model_class2.train(Data_trainClass0)\n",
    "model_class3.train(Data_trainClass0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.17079531e+01 2.75000000e+02 7.89094315e+01 ... 1.24002275e+04\n",
      "  6.62415848e+01 2.00310240e+07]\n",
      " [2.17079531e+01 2.75000000e+02 7.89094315e+01 ... 1.24002275e+04\n",
      "  6.62415848e+01 2.00310240e+07]\n",
      " [2.14732725e+01 2.75000000e+02 8.06413574e+01 ... 1.23713320e+04\n",
      "  6.61652679e+01 2.00310240e+07]\n",
      " ...\n",
      " [1.34941330e+01 2.53750000e+02 5.84715576e+01 ... 1.23409697e+04\n",
      "  6.64385223e+01 2.00112070e+07]\n",
      " [1.34941330e+01 2.53750000e+02 5.84715576e+01 ... 1.23409697e+04\n",
      "  6.64385223e+01 2.00112070e+07]\n",
      " [1.34941330e+01 2.53750000e+02 5.84715576e+01 ... 1.23409697e+04\n",
      "  6.64385223e+01 2.00112070e+07]]\n"
     ]
    }
   ],
   "source": [
    "print(Data_trainClass1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ml = [model_class1, model_class2, model_class3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Priors:\n",
      "Class 0 Prior: 0.7859472743521001\n",
      "Class 1 Prior: 0.04077301161751564\n",
      "Class 2 Prior: 0.17327971403038428\n"
     ]
    }
   ],
   "source": [
    "# Calculate the class priors\n",
    "total_samples = data_train.shape[0]\n",
    "\n",
    "# Count the number of samples in each class\n",
    "num_samples_class0 = len(Data_trainClass0)\n",
    "num_samples_class1 = len(Data_trainClass1)\n",
    "num_samples_class2 = len(Data_trainClass2)\n",
    "\n",
    "# Calculate the class priors\n",
    "prior_class0 = num_samples_class0 / total_samples\n",
    "prior_class1 = num_samples_class1 / total_samples\n",
    "prior_class2 = num_samples_class2 / total_samples\n",
    "\n",
    "print(\"Class Priors:\")\n",
    "print(\"Class 0 Prior:\", prior_class0)\n",
    "print(\"Class 1 Prior:\", prior_class1)\n",
    "print(\"Class 2 Prior:\", prior_class2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors=np.array([prior_class0,prior_class1,prior_class2])\n",
    "classifier = BayesClassifier(model_ml, priors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, labels):\n",
    "    # Nous pouvons calculez les log-probabilités selon notre modèle\n",
    "    log_prob = classifier.loglikelihood(data)\n",
    "    # Il reste à calculer les classes prédites\n",
    "    classes_pred = log_prob.argmax(1)\n",
    "    # Retournez l'exactitude en comparant les classes prédites aux vraies étiquettes\n",
    "    acc = np.mean(classes_pred == labels)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is : 78.6 % \n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is : {:.1f} % \".format(\n",
    "    100 * get_accuracy(X_train, Y_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "log_prob = classifier.loglikelihood(X_test)\n",
    "# Il reste à calculer les classes prédites\n",
    "classes_pred = log_prob.argmax(1)\n",
    "\n",
    "print(classes_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
